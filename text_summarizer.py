# -*- coding: utf-8 -*-
"""text_summarizer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/171l3vmN_2mEgLefIYCACOpREt9DAQDyE
"""

import nltk

from nltk.corpus import stopwords

from nltk.tokenize import sent_tokenize, word_tokenize

from nltk.cluster import cosine_distance

import numpy as np

from gensim.models import Word2Vec

nltk.download('punkt')
nltk.download('stopwords')

def read_text(file_path):
    with open(file_path, 'r') as file:
        text = file.read()
    return text

file_path = r"/content/sample.txt"
text_content = read_text(file_path)

def preprocess_text(text):
  sentences=sent_tokenize(text)
  stop_words=set(stopwords.words("english"))

  sentence_vectors = []
  for sentence in sentences:
    words = word_tokenize(sentence)
    words = [word.lower() for word in words if word.isalnum() and word.lower() not in stop_words]
    sentence_vectors.append(words)
  return sentence_vectors

def sentence_to_vector(model, words):
  if len(words) == 0:
    return np.zeros(100)

  word_vectors=[]
  for word in words:
    try:
      vec = model.wv[word]
      word_vectors.append(vec)
    except KeyError:
      pass

  return np.mean(word_vectors, axis=0)

def similarity_matrix(sentences, model):
  matrix=np.zeros((len(sentences), len(sentences)))
  for i in range(len(sentences)):
    for j in range(len(sentences)):
      if i != j:
        matrix[i][j]= cosine_distance(sentence_to_vector(model, sentences[i]), sentence_to_vector(model, sentences[j]))
  return matrix

def generate_summary(file_path, num_sentences=5):
  text = read_text(file_path)
  sentence_vectors = preprocess_text(text)
  model = Word2Vec(sentence_vectors, min_count=1)
  sentence_similarity_matrix = similarity_matrix(sentence_vectors, model)

  scores = np.zeros(len(sentence_vectors))
  for i in range(len(sentence_vectors)):
    scores[i] = sum(sentence_similarity_matrix[i])

  ranked_sentences = [sentence for _, sentence in sorted(zip(scores, sentence_vectors), reverse=True)[:num_sentences]]
  return " ".join([" ".join(sentence) for sentence in ranked_sentences])

file_path = "/content/sample.txt"  # Update with your file path
summary = generate_summary(file_path, num_sentences=5)
print(summary)